Alright â€” Iâ€™ll present this as a professional software requirements / specification document, the kind you could hand directly to a development team or contractor.

Clear scope, functional requirements, data model, processing flow, edge cases, and non-functional requirements.

ğŸ“¸ Media Ingestion & Organization System
Functional Specification & Technical Requirements
1. ğŸ“Œ Purpose

Develop a standalone script/application that ingests a disorganized Google Photos export (mixed folders, duplicates, sidecar JSON metadata, mixed media formats), and produces:

â€¢ A clean, date-based folder structure for long-term storage
â€¢ A deduplicated media library using perceptual hashing
â€¢ Preservation of all album and tag information
â€¢ A centralized SQLite database (single-table, JSON fields) containing all metadata and file mappings

The system must be deterministic, re-runnable, and not duplicate existing media.

2. ğŸ¯ Core Objectives

Normalize all media into a unified folder structure by date

Preserve all album information as tags

Prevent duplicate file copies

Track all original file locations

Allow querying by date, tag, and source

3. ğŸ“¥ Input

Root input directory (user-defined):

INPUT_ROOT/
 â”œâ”€â”€ Arbitrary folder structure
 â”œâ”€â”€ Album folders
 â”œâ”€â”€ Date folders
 â”œâ”€â”€ Media files (jpg, heic, png, mp4, webp, etc.)
 â””â”€â”€ JSON sidecar metadata files


User will pre-separate ownership:

INPUT_ROOT/Mine/
INPUT_ROOT/Family/


Each treated independently but with same logic.

4. ğŸ“¤ Output
4.1 Canonical Media Library
OUTPUT_ROOT/
 â”œâ”€â”€ Mine/
 â”‚    â””â”€â”€ YYYY-MM/
 â”‚         â””â”€â”€ normalized_filename.ext
 â””â”€â”€ Family/
      â””â”€â”€ YYYY-MM/


All unique media copied once only.

4.2 SQLite Database

Single database file containing all metadata.

5. ğŸ—„ Database Schema (Single Table)

Table name: media

Column	Type	Description
id	INTEGER PRIMARY KEY	
similarity_hash	TEXT UNIQUE	
canonical_path	TEXT	
owner	TEXT	
date_taken	TEXT (ISO 8601)	
date_source	TEXT	
tags	JSON (array of strings)	
source_paths	JSON (array of strings)	
status	TEXT	
notes	TEXT	
6. ğŸ”„ Processing Workflow
6.1 File Discovery

â€¢ Recursively traverse input directories
â€¢ Identify media files
â€¢ Associate sidecar JSON files where present

6.2 Date Resolution Logic (Priority Order)

Embedded metadata (EXIF/XMP/Media timestamps)

JSON metadata fields

Parent folder name parsing (regex patterns for common date formats)

If unresolved â†’ mark as missing

Store both:

â€¢ date_taken
â€¢ date_source

6.3 Similarity Hashing

â€¢ Generate perceptual hash for each media file
â€¢ Used as primary deduplication key

6.4 Tag Aggregation

Tags collected from:

â€¢ Album names in JSON metadata
â€¢ (Optional) Folder-based album inference

All tags merged into a unique set.

6.5 Deduplication & Record Handling

Lookup:

similarity_hash

If record exists:

â€¢ Append new source path if not present
â€¢ Merge new tags
â€¢ Update record
â€¢ Do not copy file

If record does not exist:

â€¢ Create new record
â€¢ Proceed to canonical copy

6.6 Canonical File Storage

Files copied to:

OUTPUT_ROOT/{owner}/{YYYY-MM}/


Filename must be deterministic and collision-safe, e.g.:

YYYYMMDD_HHMMSS_<short_hash>.ext


Canonical path stored in database.

6.7 Error Handling & Logging

System must:

â€¢ Record missing metadata
â€¢ Record failures
â€¢ Continue processing without abort

Status values:

â€¢ ok
â€¢ missing_date
â€¢ error

7. ğŸ” Re-run Behavior (Idempotency)

System must support multiple runs:

â€¢ No duplicate copies created
â€¢ Existing records updated only with new tags/sources
â€¢ Hash uniqueness enforced

8. âš  Edge Cases

â€¢ Same media in multiple folders
â€¢ Media without metadata
â€¢ Unsupported formats
â€¢ Conflicting timestamps
â€¢ Corrupted files

Must be logged, not fatal.

9. ğŸ“Š Performance Expectations

â€¢ Capable of handling 100,000+ media files
â€¢ SQLite indexed on similarity_hash
â€¢ Incremental runs should be fast

10. ğŸ” Query Capabilities

User should be able to query:

â€¢ By date range
â€¢ By tag (JSON search)
â€¢ By owner
â€¢ By duplicate source count

11. ğŸ” Data Safety

â€¢ No deletion of input files
â€¢ Copies only
â€¢ Atomic DB writes

12. ğŸ§© Extensibility (Future)

Optional later features:

â€¢ Face/person tagging
â€¢ Location clustering
â€¢ Web UI viewer
â€¢ Cloud sync automation

13. ğŸ“‹ Deliverables

Software provider shall deliver:

Executable script/application

Configuration file for input/output paths

SQLite schema creation script

Documentation for usage and re-runs

Logging output

14. ğŸ›  Suggested Technology Stack (non-binding)

â€¢ Python (or similar scripting language)
â€¢ SQLite with JSON support
â€¢ Perceptual hashing library
â€¢ Metadata parsing library

âœ… Acceptance Criteria

âœ” All unique media copied once
âœ” All album info preserved as tags
âœ” No duplicates created on rerun
âœ” Missing data clearly logged
âœ” Clean date-based output folders

If youâ€™d like, I can next provide:

ğŸ“„ A shorter â€œstatement of workâ€ version
ğŸ“ UML-style flow diagram
ğŸ§ª Test scenarios
ğŸ“Š Example SQL queries

or turn this into:

ğŸ‘‰ A GitHub-ready README/spec

Just tell me ğŸ‘